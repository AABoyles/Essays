<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>AllState Claims Severity Kernel</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="site_libs/style.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 65px;
  margin-top: -65px;
}

.section h2 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h3 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h4 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h5 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h6 {
  padding-top: 65px;
  margin-top: -65px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Anthony A. Boyles</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">Portfolio</a>
</li>
<li>
  <a href="../essays/">Essays</a>
</li>
<li>
  <a href="../code.html">Code</a>
</li>
<li>
  <a href="../about.html">About</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="../README.html">Meta</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">AllState Claims Severity Kernel</h1>

</div>


<p>[Ed. This is a transcribed and edited version of <a href="https://www.kaggle.com/aaboyles/allstate-claims-severity/beginner-friendly-simple-linear-regression/notebook">a kernel I produced</a> to compete in the <a href="https://www.kaggle.com/c/allstate-claims-severity">AllStates Claims Severity Challenge</a>.]</p>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>There are already a bunch of awesome Scripts, but I wanted to step back and work with some more rudimentary models to make sure I was doing the right data preparation.</p>
</div>
<div id="preparation" class="section level1">
<h1>Preparation</h1>
<p>Let’s start by loading our packages and data.</p>
<pre class="python"><code>import numpy as np
import pandas as pd
import matplotlib.mlab as mlab
import matplotlib.pyplot as plt
from scipy.stats import skew, boxcox
import statsmodels.formula.api as smf
import xgboost as xgb
from bayes_opt import BayesianOptimization
from sklearn.metrics import mean_absolute_error

# Load Training Data
train = pd.read_csv(&#39;../data-cache/Allstate/train.csv&#39;, dtype={&#39;id&#39;: np.int32})

# Load Test Data
test = pd.read_csv(&#39;../data-cache/Allstate/test.csv&#39;, dtype={&#39;id&#39;: np.int32})</code></pre>
<p>Nomenclature note: The outcome variable for this competition is ‘loss’. (If you read much machine learning literature, you’ve probably heard the term <em>loss</em> as in ‘loss function’.) That isn’t exactly what we mean in this context. The ‘loss’ variable in this case literally refers to the amount AllState lost on the settlement. Wherever you see ‘loss’ in this document, assume I’m talking about the amount AllState lost, and not the output of a loss function.</p>
<p>Now, prediction is easier on an outcome that’s normally distributed. Let’s check to see if this data is:</p>
<pre class="python"><code>plt.hist(train[&#39;loss&#39;], 30, normed=1)
plt.xlabel(&#39;Loss&#39;)
plt.ylabel(&#39;Probability&#39;)
plt.title(&#39;Distribution of Losses&#39;)
plt.show()</code></pre>
<p>Wow. That isn’t normally distributed at all: it’s super skewed.</p>
<pre class="python"><code>skew(train[&#39;loss&#39;])</code></pre>
<p>Any skew greater than one should probably catch your attention. Luckily, we have a simple counterspell! Let’s log-transform the ‘loss’ variable.</p>
<pre class="python"><code>train[&#39;log_loss&#39;] = np.log(train[&#39;loss&#39;])

plt.hist(train[&#39;log_loss&#39;], 30, normed=1)
plt.xlabel(&#39;Log(Loss)&#39;)
plt.ylabel(&#39;Probability&#39;)
plt.title(&#39;Distribution of Log(Loss)es&#39;)
plt.show()</code></pre>
<p>Much Better. Now, what about our input variables? Are they similarly skewed?</p>
<pre class="python"><code>features_numeric = test.dtypes[test.dtypes != &quot;object&quot;].index
features_skewed = train[features_numeric].apply(lambda x: skew(x.dropna()))
features_skewed</code></pre>
<p>Some of them, yeah. We can fix that by taking their log-transforms as well, but log is sort of a blunt instrument. It’s easily reversible, which makes it good for the outcome. But the Box-Cox transform is a better tool for modifying our inputs. Let’s apply it to any features with a skew greater than, say, .2</p>
<pre class="python"><code>features_skewed = features_skewed[features_skewed &gt; 0.2]
for feat in features_skewed.index:
    train[feat], lam = boxcox(train[feat] + 1)
    test[feat] = boxcox(test[feat] + 1, lam)

features_skewed = train[features_numeric].apply(lambda x: skew(x.dropna()))
features_skewed</code></pre>
<p>That eliminated much of the skewness. Before we move on, however, I’d like to call attention to the way we handle lam in the above block. We let boxcox figure out the optimal lam using our training data, and then force it to use that same lam on the test data, even if it isn’t necessarily optimal for the test data. The alternative approach is to bind train and test together, perform these transformations on the entire set, and then split them back apart when it comes time to build models. I’ve opted not to for the benefit of clarity, but possibly at the cost of some small modeling advantage.</p>
<p>Now, we have some categorical features we need to handle. The textbook approach to Linear Regression says you can leave categorical variables in, provided you do something like one-hot encode them and leave out the smallest category. Personally, I prefer to replace the category with the arithmetic mean of its corresponding subset of outcomes.</p>
<pre class="python"><code>features_categorical = [feat for feat in test.columns if &#39;cat&#39; in feat]

for feat in features_categorical:
    a = pd.DataFrame(train[&#39;log_loss&#39;].groupby([train[feat]]).mean())
    a[feat] = a.index
    train[feat] = pd.merge(left=train, right=a, how=&#39;left&#39;, on=feat)[&#39;log_loss_y&#39;]
    test[feat] = pd.merge(left=test, right=a, how=&#39;left&#39;, on=feat)[&#39;log_loss&#39;]

features_categorical = test.dtypes[test.dtypes == &quot;object&quot;].index</code></pre>
<p>There’s just one more thing to check on. Linear Regression generally doesn’t handle missing values very well. Let’s see if we have any:</p>
<pre class="python"><code>counts = train.count()
len(counts[counts &lt; train.shape[0]])</code></pre>
<p>Not in the training dataset. Let’s check test now:</p>
<pre class="python"><code>counts = test.count()
len(counts[counts &lt; test.shape[0]])</code></pre>
<p>Rats. OK, Rather than design a elaborate solution, I’m just going to drop any columns with missing values.</p>
<pre class="python"><code>temp = test.dropna(1)
counts = temp.count()
len(counts[counts &lt; temp.shape[0]])</code></pre>
</div>
<div id="linear-model" class="section level1">
<h1>Linear Model</h1>
<p>Cool. Now, we’re ready to make a model.</p>
<pre class="python"><code>model = smf.ols(&#39;log_loss ~ &#39; + &#39; + &#39;.join(temp.columns), data=train).fit()
model.summary()</code></pre>
<p>There’s a lot of useful information here. However, since this is a prediction challenge, I’m not interested in most of it. Instead, I’m interested in how well it can predict new values. To do that…</p>
<pre class="python"><code>yhat = np.exp(model.predict(test))</code></pre>
<p>Note that we call np.exp on our model predictions. Remember how we log-transformed ‘loss’ up at the beginning of this script? Exponentiating the outcome sort of undoes that, so our predictions will be on the same scale as ‘loss’ instead of ‘log_loss’. Forgetting this step is a really good way to get a terrible score. Now that we have some predictions, let’s write them out and score them!</p>
<pre class="python"><code>result = pd.DataFrame({&#39;id&#39;: test[&#39;id&#39;].values, &#39;loss&#39;: yhat})
result = result.set_index(&#39;id&#39;)
result.to_csv(&#39;simplelmprediction.csv&#39;, index=True, index_label=&#39;id&#39;)</code></pre>
<p>If you submit that, it should give you a score something like 1245.99. That’s a bit worse than the Random Forest Benchmark (which isn’t surprising). To improve upon that, we’re going to need a more powerful machine learning technique. In Kaggle competitions, that usually means either Deep Learning or XGBoost. Let’s try XGBoost.</p>
</div>
<div id="xgboosted-model" class="section level1">
<h1>XGBoosted Model</h1>
<p>One important difference between Linear models and most advanced machine learning techniques is the tuning parameters. Once you get past massaging the data, linear models have no parameters. You never need to estimate the optimal number of rounds, passes, trees, branches, or nodes. However, other techniques will require at least some of these configuration parameters, and will probably behave poorly if the parameters are far-removed from their optimal values (or combinations). XGBoost is such a technique.</p>
<p>In order to fit an XGBoost model, we need to set a <em>learning_rate</em> (also sometimes called “eta”), a <em>gamma</em>, a <em>minimum child weight</em>, a <em>col sample by tree</em>, a <em>subsample</em>, and a <em>maximum depth</em>. Exploring all of these would be hard. Exploring all combinations of these would be impractical. So, instead of trying to exhaust the possibile combinations with a given level of precision (a grid search), let’s use an optimizer.</p>
<pre class="python"><code># Load Training Data
train_labels = np.array(train[&#39;log_loss&#39;])
train.drop(train.columns[[-1,-2]], 1, inplace = True)
d_train_full = xgb.DMatrix(train, label=train_labels)

# if you&#39;re paranoid about overfitting, increase this.
n_folds = 10

# if you see metrics dropping precipitously until the end, increase this.
n_rounds = 100

# Set this to anything you want.
seed = 10

def xg_eval_mae(yhat, dtrain):
    y = dtrain.get_label()
    return &#39;mae&#39;, mean_absolute_error(np.exp(y), np.exp(yhat))

def fitXGBoost(eta = .1, gamma = .5, min_child_weight = 4, colsample_bytree = .3, subsample = 1, max_depth = 6):
    model = xgb.cv({
        &quot;silent&quot;: True,
        &quot;learning_rate&quot;: eta,
        &quot;gamma&quot;: gamma,
        &quot;min_child_weight&quot;: min_child_weight,
        &quot;colsample_bytree&quot;: colsample_bytree,
        &quot;subsample&quot;: subsample,
        &quot;max_depth&quot;: int(max_depth),
        &quot;early_stopping_rounds&quot;: 20,
        &quot;seed&quot;: seed
        }, d_train_full, n_rounds, n_folds, feval = xg_eval_mae)
    return(-model.iloc[-1,0])

bo = BayesianOptimization(fitXGBoost, {
    &#39;eta&#39;: (.01, .5),
    &#39;gamma&#39;: (0, 4),
    &#39;min_child_weight&#39;: (1, 5),
    &#39;colsample_bytree&#39;: (.01, 1),
    &#39;subsample&#39;: (.5, 1),
    &#39;max_depth&#39;: (3, 12)
})

bo.maximize(init_points = 60, n_iter = 120)</code></pre>
<pre class="python"><code># Discovered by the hyperoptimize.py script
params = {
    &quot;colsample_bytree&quot;: .9921,
    &quot;eta&quot;: .0995,
    &quot;gamma&quot;: 3.8581,
    &quot;max_depth&quot;: 11,
    &quot;min_child_weight&quot;: 1.0065,
    &quot;subsample&quot;: 1
}

def xg_eval_mae(yhat, dtrain):
    y = dtrain.get_label()
    return &#39;mae&#39;, mean_absolute_error(np.exp(y), np.exp(yhat))

res = xgb.cv(params, train_d, n_rounds, n_folds, early_stopping_rounds = 15, seed = seed, feval = xg_eval_mae)

n_rounds = res.shape[0] - 1

model = xgb.train(params, train_d, n_rounds)

# Write the Results
result = pd.DataFrame(np.exp(model.predict(test_d)), columns=[&#39;loss&#39;])
result[&quot;id&quot;] = test[&#39;id&#39;].values.astype(np.int32)
result = result.set_index(&quot;id&quot;)
result.to_csv(&#39;outputs/hyperoptimizedxgb.csv&#39;, index=True, index_label=&#39;id&#39;)</code></pre>
</div>
<div id="bonus-golfed-solution" class="section level1">
<h1>Bonus: Golfed Solution</h1>
<p>Bonus Addendum: Just for fun, here’s a <a href="https://en.wikipedia.org/wiki/Code_golf">golf</a> solution which scores a bit worse than the Linear Model, but generates predictions in the smallest python script I could write.</p>
<pre class="python"><code>import pandas as p
import statsmodels.formula.api as s
e=p.read_csv(&#39;../input/test.csv&#39;).dropna(1)
p.DataFrame({&#39;id&#39;:e[&#39;id&#39;].values,&#39;loss&#39;:s.ols(&#39;loss~&#39;+&#39;+&#39;.join([c for c in e.columns if &#39;cont&#39; in c]),data=p.read_csv(&#39;../input/train.csv&#39;)).fit().predict(e)}).to_csv(&#39;o.csv&#39;,index=False)</code></pre>
</div>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109466857-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-109466857-1');
</script>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
