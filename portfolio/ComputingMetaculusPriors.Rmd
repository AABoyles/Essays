---
title: "Computing Metaculus Priors"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

Imagine there's a prediction game where all questions are of the format "Will X happen by y" where x is some event and y is some date. Given a randomly selected question (that you don't get to read), what should your prediction be?

Given no other information, you should probably guess 50%. But the fact that you can't read the question doesn't mean you don't have any more information. Perhaps none of the events had ever occurred by the dates, meaning you should assign a low probability to your random, unknown question. In other words, you can compute a prior *on the game itself*. Let's give this a try with [Metaculus](https://www.metaculus.com/)!

Metaculus itself has done this twice:

* [Which percentage of Metaculus questions resolving from October 1st to December 31st 2018 (inclusive) will resolve positively? ](https://www.metaculus.com/questions/1475/which-percentage-of-metaculus-questions-resolving-from-october-1st-to-december-31st-2018-inclusive-will-resolve-positively/)
* [Which percentage of Metaculus questions resolving in Q1 2019 will resolve positively?](https://www.metaculus.com/questions/1490/which-percentage-of-metaculus-questions-resolving-in-q1-2019-will-resolve-positively/)

## API Scraping

To start, we can get the data by querying Metaculus' Track Record API.

```{r}
library(readr)
library(dplyr)
library(DT)

if(file.exists('../data-cache/metaculus-questions.csv')){
  binaryQuestions <- read_csv('../data-cache/metaculus-questions.csv')
} else {
  library(jsonlite)
  binaryQuestions <-
    fromJSON('https://www.metaculus.com/questions/track-record/export/') %>%
    select(-categories)
  write_csv(binaryQuestions, '../data-cache/metaculus-questions.csv')
}

binaryQuestions %>%
  select(title, qtype, resolution) %>%
  datatable()
```

OK! Let's get to the analytics!

## Binary Frequencies

Not all questions on Metaculus are percentage predictions on discrete events. Sometimes you're predicting a number (e.g. How many X by Y). For simplicity's sake, let's just start with the questions that can be resolved with a simple yes or no.

```{r}
library(pander)

binaryQuestions <- questions %>%
  filter(qtype=='binary') 

freqTable <- binaryQuestions %>%
  group_by(resolution) %>%
  summarise(count = n())

frequencies <- freqTable$count

freqTable %>%
  pander()
```

(0 and 1 correspond to negative and positive resolutions respectively, and -1 is an ambiguous resolution.)

So we see that a majority of questions (`r frequencies[2]` out of `r nrow(binaryQuestions)`) ) are resolved negatively. So your prior on a randomly-selected, binary-outcome Metaculus question should be something like the proportion of (unambiguously resolved) questions which resolve positively, or `r round(100*frequencies[3]/(frequencies[2]+frequencies[3]))`%.

Now, ideally resolutions would be uniformly distributed (so you can't exploit information like this), but asking good questions is difficult. Has the Metaculus community gotten better at this over time?

## Binary Frequencies over time

If the distribution is getting closer to 50-50 over time, then eventually leveraging a Metaculus prior won't work (or rather, won't improve intuition). Alternately, Perhaps Metaculus is converging on a specific frequency, in which case this exercise will prove to be **super useful**.

```{r}
library(plotly)

binaryQuestions %>%
  filter(resolution >= 0) %>%
  arrange(resolve_time) %>%
  mutate(
    rank = row_number(),
    resolutions = cumsum(resolution),
    ratio = resolutions/rank
  ) %>%
  plot_ly(x = ~as.Date(resolve_time), y = ~ratio, mode="lines") %>%
  layout(
    yaxis = list(title = "Positive Resolution Proportion"),
    xaxis = list(title = "Time")
  )
```

Excitingly, it appears to be the latter! That "Metaculus Prior" of `r round(100*frequencies[3]/(frequencies[2]+frequencies[3]))`% seems to be rather strikingly stable at just below 0.3 over time.

## Continuous Frequencies

But what about those questions that don't resolve with a simple "yes" or "no"? Is there a meaningful prior we can extract from them?

To begin to invesitgate this, let's think about what Metaculus continuous predictions look like.

[![Eurosceptics Elected to 2019 EU Pariament](https://aaboyles.github.io/Essays/imgs/EuroscepticsInEUParliament2019.PNG)](https://www.metaculus.com/questions/1510/how-many-seats-will-the-various-eurosceptic-groups-collectively-achieve-for-the-eu-parliament-election-2019/)

Here's Metaculus' prediction about [the number of Eurosceptics who will be elected to the EU Parliament in 2019](https://www.metaculus.com/questions/1510/how-many-seats-will-the-various-eurosceptic-groups-collectively-achieve-for-the-eu-parliament-election-2019/). Note the bounds on the x-axis. Those numbers make perfect sense for the European Parliament, but wouldn't generalize to a question with a radically different scale (e.g. [How many youtube reviews will Mariah Carey's "All I want for Christmas is you" get?](https://www.metaculus.com/questions/1606/how-many-youtube-views-will-all-i-want-for-christmas-is-you-have-on-january-6th-2019/)). So, to get anything resembling a viable prior, we're going to need to normalize all the ranges to a common set of bounds. 0 to 1, perhaps?

```{r}
questions %>%
  filter(
    qtype=="num",
    resolution >= 0
  ) %>%
  dplyr::mutate(
    scaleMin = as.numeric(possibilities.scale.min),
    scaleMax = as.numeric(possibilities.scale.max),
    range = scaleMax - scaleMin,
    centered = resolution - scaleMin,
    scaled = centered / range
  ) %>%
  filter(scaled >= 0) ->
  continuousQuestions

plot_ly(continuousQuestions, x=~scaled) %>% add_histogram()
```

We don't have a ton of data points to go off of here, but it looks like continuous questions tend resolve around the low end of the scale. Again, don't invest too much in this assessment--there simply aren't enough resolved, continuous questions to go off of with much confidence.

## Conclusion

So, returning to our motivating thought experiment, if you're confronted with a random, binary question, your first guess shouldn't be 50%--it should be `r round(100*frequencies[3]/(frequencies[2]+frequencies[3]))`%. If you're estimating a number, shoot for the low end of the spectrum. That being said, this is a just a minimally informative prior taken by assessing the outside view on Metaculus itself. Almost literally any information about the specific question should trigger a strong update (relative to the strength of this evidence).

Sadly, Metaculus-founder Anthony Aguirre has [noted this trend](https://www.metaculus.com/questions/935/discussion-topic-what-features-should-metaculus-add-may-2018-edition/#comment-6564):

> Our trends of negative resolutions to questions is getting tiresome, and leaving little data at the upper end of the calibration curve. This is a plea/suggestion to when formulating your question consider whether it could be phrased in a way that is equivalent, but where the odds (by your own estimation) are above rather than below 50%. For some questions this is awkward, but for many it could be a small tweak.

[I proposed](https://www.metaculus.com/questions/935/discussion-topic-what-features-should-metaculus-add-may-2018-edition/#comment-18007) that the Moderators could apply a heavier hand to accomplish this:

> Balance the distribution of outcomes. Right now, binary questions on Metaculus are resolved as "No" ~70% of the time. A distribution closer to 50% will be less game-able. One strategy to accomplish this is to flip a coin on every binary question suggestion. If heads, mods could reverse the polarity of the question before publishing it (see Will Ocean Cleanup fail to deliver 60 systems... for an example of what I mean). If they're clever about it, it might not even be obvious to a casual reader that this type of transformation had happened.

> I realize this places an additional burden on the mods, and am very curious if anyone else can think of a way to accomplish roughly the same effect without the costs.

No answers have yet been forthcoming.