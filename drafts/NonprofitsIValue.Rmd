---
title: "Nonprofits I Value"
---

# Introduction

The Effective Altruism Community does a good job of assessing which charities are most able to turn _funds_ into _effects_. Cost per life saved. Cost per Averted DALY Loss. But there exist a few domains in which the potential for contributions to the well-being of humanity is enormous, though they aren't typically identified by the Effective Charity Evaluators as being as worthy as the popular targets for effective funding. There are various reasons for this: research constraints, conservatism about issue advocacy (i.e. people will donate to end malaria, but not to extreme life extension), avoiding self-aggrandizement... These reasons, however, are *not* that the charity or opportunity lacks the possibility of having a positive effect on the order of magnitude of the currently top-rated charities.

# Existential Risk Reduction

The moral consequence of an existential risk successfully eliminating humanity dwarfs the moral consequence of any other bad thing.

* [Machine Intelligence Research Institute](https://intelligence.org/) - What if an alien sent us a message: "We'll be arriving sometime in the next 100 years or so. You can't stop us. If you solve this one tiny math problem, we'll make everything about your lives better. Otherwise, we'll probably just kill you." I'd get to solving that math problem as soon as possible. Now replace alien with Artificial Intelligence, and you have exactly the problem we're dealing with. MIRI is the group that's solving the math problem.
* [Future of Life Institute](http://futureoflife.org/get-involved/) -
* [Future of Humanity Institute](http://www.fhi.ox.ac.uk/support-fhi/) - One of the important factors in the ongoing effort to solve the problems of Friendly Artificial Intelligence will undoubtedly be Nick Bostrom's book, Superintelligence.
* [Center for the Study of Existential Risk](http://cser.org/) - While CSER isn't explicitly in the business of mitigating existential risks, there's a lot to be said for studying them.
* [Center for Applied Rationality](http://rationality.org/) - This may seem an odd target for intended high-impact donations. After all, rationality is a good thing, but how can it possibly be as worthy a cause as buying Long Lasting Insecticide Nets? The Center for Applied Rationality doesn't advertise this fact, but one of its' primary goals is to be a possible solution to MIRI's recruitment problem. CFAR was founded by some MIRI employees (and some of their close associates) for the purpose of [identifying people with the potential to become AI Safety Researchers](http://rationality.org/miri-summer-fellows-2016/).

# Life Extension

We calculate the moral cost of death as the difference between the age of a person at their death, and their expected lifespan if they hadn't been killed by whatever bad thing killed them. The traditional approach to effective altruism is to identify inexpensive approaches to stopping bad things from killing people. But what if we could extend the expected lifespan indefinitely? A single person who will live forever could experience billions of DALYs.

* [SENS Foundation](http://www.sens.org/) - The best-positioned group to engineer viable pathways to long-term Life Extension right now is the SENS Foundation (headed by well-known transhumanist Aubrey de Grey).
* [Methuselah Foundation](https://www.mfoundation.org/) - Another project with Aubrey de Grey's fingerprints on it, this angel firm doles out investments to biotech firms it judges to be likely to make a substantive contribution to life extension research.
* [Life Extension Advocacy Foundation](http://www.lifeextensionadvocacyfoundation.org/donate/)
* [LifeSpan.io](http://www.lifespan.io/) - This is a croundfunding platform for Life-extension research projects.
* [Alcor](http://alcor.org/) and the [Cryonics Institute](http://www.cryonics.org/) - Life Extension for those who will die before they get the opportunity to live indefinitely. I don't advocate for giving to Cryonics providers in excess (it's far less efficient than giving to the SENS Foundation), but I do believe that making the requisite financial contribution to become a brain stem or full-body donor is a good idea.

# Evidence-Based Policy Advocacy

Effective Altruism is only a small part of an effective _world_. The US Government commands a budget of trillions of dollars _annually_. By contrast, the Bill and Melinda Gates Foundation controls an endowment of only $43 billion. Thus swaying decisions of the US Government, even by tiny amounts, can result huge funding benefits for effective approaches to the social problems the government is interested in addressing.

* [Coalition for Evidence-Based Policy](http://coalition4evidence.org/)
* [Campbell Collaboration](http://www.campbellcollaboration.org/)

# Effective Charity Evaluators

As Benjamin Todd [recently pointed out](https://80000hours.org/2015/06/donating-to-giving-what-we-can-is-higher-impact-than-donating-to-givewell-recommended-charities/), the amount of money directed to effective charities based on recommendations by Giving What We Can far exceeded GWWC's annual budget. That implies a multiplier effect: the evaluators have proven themselves able to turn small amounts of money into huge donations for their targeted charities. That makes them more effective than the charities they recommend (albeit, only for now and within fairly stark limitations).

* [GiveWell](http://www.givewell.org/)
* [Center for Effective Altruism](https://centreforeffectivealtruism.org/)
  * [Giving What We Can](http://www.givingwhatwecan.org/)
  * [80,000 Hours](http://www.80000hours.org/)
  * [Global Priorities Project](http://globalprioritiesproject.org/)
* [The Life You Can Save](http://www.thelifeyoucansave.org/)
* [Animal Charity Evaluators](http://www.animalcharityevaluators.org/) - I didn't put any animal charities on the first drafts of this list because I didn't see animal welfare as occupying any level of moral importance that was meaningfully comparable to Existential Risk or Human Life. However, I do identify strongly with the sentiment that the consumption of animal products causes animals harm, and this should minimized. Moreover, the cost of offsetting an individual meat-eaters' consumption is [very, very low](http://slatestarcodex.com/2015/09/23/vegetarianism-for-meat-eaters/).

# Ethical Investment

The EA Community hasn't spent a lot of time considering the Ethical Investment movement. This is for the simple reason that the world is getting better; therefore, donations today will probably have higher impact than donations in 20 years. That said, many of us do keep long-term investments, whether in the guise of 401(k)s, IRAs, or individually held shares of Mutual Funds, Stocks, or other investments. Because of this, I think that Ethical Investment for the effective altruism community may a valuable avenue to achieving _additional_ social good.

* [PaxWorld Investments](http://www.paxworld.com/) - A variety of fund options focused on specific issues (Women's rights, Sustainability) as well as more general options (Growth-focused, Bonds, etc) all with stringent moral requirements.

# Stuff I Value Independently of Social Good

Sometimes the social good of a publicly-funded institution isn't comparable to EA Causes. My favorite Internet radio broadcaster is never going to save as many lives as a distribution of Malaria nets. It will never lift African villagers from poverty and destitution. But I value the product it generates, and it's ability to continue doing so is contingent upon people donating to the service. I do not donate to these and likely never will, but I greatly appreciate that other people do, because I personally benefit from them.

* [Wikimedia Foundation](https://donate.wikimedia.org/w/index.php?title=Special:FundraiserLandingPage)
* [National Public Radio](http://www.npr.org/about-npr/187533209/major-gifts)
* [Soma.fm](http://somafm.com/support/?fp30px)
