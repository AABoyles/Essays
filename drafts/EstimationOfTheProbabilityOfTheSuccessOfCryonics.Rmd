---
title: "Estimation of the Probability of the Success of Cryonics"
---

# Introduction

```{r, results='asis', eval=FALSE}
source("infobox.R")
meta <- list(
  "Status" = "Incomplete",
  "Epistemic Status" = "Highly Speculative"
  #"Last Revision" = file.info("EstimationOfTheProbabilityOfTheSuccessOfCryonics.Rmd")$mtime
)
infobox(meta)
```

Imagine you are living in a small European village in 1347\. You've heard rumors of a terrible disease ravaging other distant villages. Then one day, another villager falls ill with severe malaise, headache, shaking chills, fever, and painful, swollen bulbs near her joints. The other villagers decry her sinfulness, and avoid her entire family like (ahem) the plague. It doesn't matter. Others fall victim. The unaffected take to carrying flowers right below their noses to perfume the stench of dying and decaying bodies. Before long, you feel a crushing headache. You can't motivate yourself out of your bed at sunrise. By nightfall, it's clear you're infected. The next morning, it's clear you're not long for this world. You die before supper. Luckily, [the dead cart was coming around the next day](https://youtu.be/grbSQ6O6kbs). Now, imagine that instead of coming down with this terrible disease in 1347, you come down with it in 2016\. Feeling worse than a run-of-the-mill cold, you make your way to the nearest hospital. They determine that you have a _Yersinia Pestis_ infection, and [inject you with broad-spectrum antibiotics](https://en.wikipedia.org/wiki/Yersinia_pestis#Treatment). Within minutes you feel a little bit better. Within a week (and a few more injections), you're all better.

OK, stay with me. What if you got the plague in 1347, but there was a way you could be transported to 2016 for treatment? For those of us in 2016, I think the obvious answer is "Great! Sign me up!" For the poor denizens of 1347, the much likelier answer is "That will never work." As it happens, we still die of a long list of things from which we don't yet know how to prevent ourselves from dying. But we've developed a pretty good idea about how to transport ourselves arbitrarily far into the future to assure our survival. It's called cryonics.

Let's investigate _why_ it might not work. Cryonics can fail in broadly three ways: First, cryonics may not be able to protect us from information-theoretic death. This is the most obvious failure mode, and the one that people most strongly consider in criticisms of cryonics. However, it is also the _least likely_ failure mode. Our brains contain an arrangement of matter which implements a _mind_. If we can figure out how to capture the arrangement of matter in sufficient resolution (likely supramolecular), we can reimplement the mind by emulating the physics of that matter in a computer. The only way this can fail over the long run is if mind degradation occurs so quickly upon death that, even factoring in damage, the data is irrecoverable. Research suggests that this is not the case. I personally estimate this probability is around $10^{-2}$.

Second, cryopreservation is a wager that human-friendly technological progress continues. Humanity could cease to make technological progress, or go extinct. The probability of human technical achievement "topping out" before preserved humans are recoverable seems pretty implausible to me, but I admit that the probability must be non-zero. As an example case, a luddite world government could form that was able to rapidly build strong norms and enforcement institutions against free speech, dissent, or technical innovation. There are weak precedents for governments that successfully demonstrate this type of norm- and institution- building on the national scale; the Soviet Union and North Korea both come to mind. However, these examples should also inform us about the _implausibility_ of these concerns: the Soviet Union collapsed, and the North Korean regime has built its arguably tenuous grasp on power by appealing to highly specific cultural sensibilities that would not generalize globally. Human extinction isn't the most widely investigated topic, but it's widely agreed to be _possible_. I tend to think that the probability of us surviving the bootstrapping of superintelligent machines is less favorable than a coin flip. Nick Bostrom estimates it to be around 40%.

In order for this to be true, we need to fail to build the technology to recover the information contained in the brain in the entire future of the Universe. If the universe only continues to be habitable for [another 20 billion years](https://en.wikipedia.org/wiki/Chronology_of_the_universe#Big_Rip:_.E2.89.A520_billion_years_from_now) (a conservative estimate!), this means that we have 20 billion years to figure out the technology to read the information encoded within the brain.

Third, belief in successful cryonics is predicated on the belief that cryonics vendors will be able to provide uninterrupted access to the conditions required to maintain cryostasis. We know this is a real failure risk because it has [already happened](http://www.alcor.org/Library/html/suspensionfailures.html). The fact that suspension failure has ever happened scares the hell out of me.

If you estimate the expected value of signing up for cryonics to be positive, [go sign up right now](http://www.alcor.org/). If not, please consider organ and estate donations. After all, the fact that you decided to die with near certainty shouldn't mean that you can't do some good on your way out.
